# LLM Fine-Tuning Showdown: LoRA vs QLoRA vs Full Fine-Tuning

**Research Question**: Which LLM fine-tuning method provides the best trade-off between accuracy, cost, and resource requirements for practical applications?

## ğŸ¯ Objective

Compare three fine-tuning methods on a resume classification task:
- **Full Fine-Tuning**: Update all model parameters
- **LoRA**: Low-Rank Adaptation (parameter-efficient)
- **QLoRA**: Quantized LoRA (memory-efficient)

## ğŸ† Key Results

**Hardware**: NVIDIA A100-SXM4-80GB (Google Colab Pro+)

**Dataset**: 962 resumes across 25 job categories (70/15/15 split)

**Base Model**: mistralai/Mistral-7B-v0.1

### Performance Summary:

```
============================================================
FINAL COMPARISON
============================================================
Baseline:     73.00% | 0h training
Full FT:      100.00% | 0.20h training (12 min)
LoRA:         93.79% | 0.06h training (3.7 min) - FASTEST âš¡
QLoRA:        94.48% | 0.10h training (6 min) - BEST EFFICIENCY ğŸ¯
============================================================
```

| Method | Accuracy | F1-Score | Training Time | GPU Memory | Trainable Params |
|--------|----------|----------|---------------|------------|------------------|
| **Baseline** | 73.00% | 0.7426 | 46s | N/A | N/A |
| **Full FT** | **100.00%** ğŸ¥‡ | **1.0000** | 12 min | ~60 GB (75%) | 7.11B (100%) |
| **QLoRA** | **94.48%** ğŸ¥ˆ | **0.9392** | 6 min | **~15 GB (17%)** ğŸ¯ | 3.5M (0.05%) |
| **LoRA** | **93.79%** ğŸ¥‰ | **0.9306** | 3.7 min | ~80 GB (98%) âš¡ | 3.5M (0.05%) |

### Key Findings:

1. âœ… **Full FT**: Perfect 100% accuracy - Gold standard, but expensive (60GB GPU, 7.11B params)
2. âœ… **QLoRA**: 94.48% accuracy with MAXIMUM memory efficiency (~15GB, 17% util) - **Best for production!** ğŸ¯
3. âœ… **LoRA**: Fastest training (3.7 min), but uses 80GB GPU memory (98% util) - more than Full FT!
4. âœ… **Surprising Finding**: LoRA uses MORE memory than Full FT despite training only 0.05% of params!
5. âœ… **Winner**: QLoRA strikes the best balance - beats LoRA accuracy with 80% less GPU memory!

## ğŸ“Š Task

**Resume Classification**: Categorize resumes into 25 job categories

**Dataset**: UpdatedResumeDataSet.csv from Kaggle (962 samples)

**Evaluation Metrics**:
- Accuracy & F1-score âœ…
- Training time âœ…
- GPU memory usage âœ…
- Trainable parameters âœ…
- Model size âœ…

## ğŸ—‚ï¸ Project Structure

```
llm-finetuning-research/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Kaggle resume dataset
â”‚   â””â”€â”€ processed/        # Train/val/test splits
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/            # Data processing scripts
â”‚   â”œâ”€â”€ training/        # Training scripts for each method
â”‚   â””â”€â”€ evaluation/      # Evaluation and analysis
â”œâ”€â”€ models/              # Saved models and checkpoints
â”œâ”€â”€ experiments/results/ # Experimental results and logs
â”œâ”€â”€ notebooks/           # Analysis notebooks
â””â”€â”€ papers/drafts/       # arXiv paper drafts
```

## ğŸš€ Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Download dataset** (from Kaggle):
   - Dataset: Resume Dataset or similar
   - Place in `data/raw/`

3. **Process data**:
   ```bash
   python src/data/prepare_dataset.py
   ```

4. **Run experiments**:
   ```bash
   # Full fine-tuning
   python src/training/full_finetune.py

   # LoRA
   python src/training/lora_finetune.py

   # QLoRA
   python src/training/qlora_finetune.py
   ```

5. **Evaluate**:
   ```bash
   python src/evaluation/evaluate_model.py
   ```

## ğŸ“Š Weights & Biases Tracking

All experiments tracked with W&B:

- **Project**: [llm-finetuning-showdown](https://wandb.ai/birla2006-independent-researcher/llm-finetuning-showdown)
- **Baseline Run**: [sz78gpo9](https://wandb.ai/birla2006-independent-researcher/llm-finetuning-showdown/runs/sz78gpo9)
- **Full FT Run**: [e45zpfah](https://wandb.ai/birla2006-independent-researcher/llm-finetuning-showdown/runs/e45zpfah)
- **LoRA Run**: [wia3xlss](https://wandb.ai/birla2006-independent-researcher/llm-finetuning-showdown/runs/wia3xlss)
- **QLoRA Run**: [9gaihret](https://wandb.ai/birla2006-independent-researcher/llm-finetuning-showdown/runs/9gaihret)

**ğŸ“„ W&B Report**: Comprehensive 5-page PDF report with all visualizations available at `wandb_report.pdf` - includes:
- Accuracy, F1, precision, recall comparison charts
- Training curves and convergence analysis
- GPU utilization and system metrics
- Final performance comparison across all methods

## ğŸ“ Notebooks

All training notebooks are in the `notebooks/` directory:
- `Setup_and_Baseline.ipynb` - Zero-shot baseline
- `Full_FineTuning.ipynb` - Full fine-tuning (100% accuracy)
- `LoRA_FineTuning.ipynb` - LoRA training (93.79% accuracy)
- `QLoRA_FineTuning.ipynb` - QLoRA training (94.48% accuracy)

**Hardware**: Google Colab Pro+ with A100-SXM4-80GB GPU


## ğŸ“§ Contact

**Researcher**: Birla Murugesan
**Institution**: Independent Researcher
**Project**: LLM Fine-Tuning Comparative Study
**Date**: December 2025
